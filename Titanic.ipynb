{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NzALKGrK7Es",
        "colab_type": "text"
      },
      "source": [
        "# Titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UipCTgPqLGch",
        "colab_type": "text"
      },
      "source": [
        "## Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj4rWPkxK2CK",
        "colab_type": "code",
        "outputId": "3d5a1099-d1de-4fdc-dc18-d0c8af34d3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sl\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(tf.__version__)\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "print(sl.__version__)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "1.0.4\n",
            "1.18.4\n",
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_qF84goLLsn",
        "colab_type": "text"
      },
      "source": [
        "## Download dei Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L1YSjiQYdCr",
        "colab_type": "text"
      },
      "source": [
        "Importiamo i dataset necessari per l'addestramento e per il test della rete neurale:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJ8c9cMLPRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/rirolli/Titanic/master/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/rirolli/Titanic/master/test.csv'\n",
        "url_test_y = 'https://raw.githubusercontent.com/rirolli/Titanic/master/gender_submission.csv'\n",
        "\n",
        "titanic_load_train = pd.read_csv(url_train)\n",
        "titanic_load_test = pd.read_csv(url_test)\n",
        "titanic_load_test_label = pd.read_csv(url_test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJKoI3SiL8u8",
        "colab_type": "code",
        "outputId": "36c9416b-84db-4d60-b083-c4d0b15f9358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Stampa delle prima 5 righe del dataset di train\n",
        "titanic_load_train.head()"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Y1iLExMJD6",
        "colab_type": "text"
      },
      "source": [
        "## Ottimizzazione del Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGd-HCLKYtGO",
        "colab_type": "text"
      },
      "source": [
        "Preparazione dei dati rendendoli tutti in forma numerica in quanto il modello della rete neurale di tensorflow esegue calcoli solo su numeri e non sulle stringhe. Inoltre eliminiamo la colonna 'Name' poiché non utile ai fini del problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI-ejfNWMMA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rimozione della colonna dei nomi delle persone in quanto non è necessaria\n",
        "# ai fini dell'apprendimento della rete\n",
        "titanic_load_train.pop('Name')\n",
        "titanic_load_test.pop('Name')\n",
        "\n",
        "# Codifica di tutti i dati dei dataset titanic_load_train e titanic_load_test\n",
        "for elem_train in titanic_load_train:\n",
        "  titanic_load_train[elem_train] = (pd.Categorical(titanic_load_train[elem_train])).codes\n",
        "\n",
        "for elem_test in titanic_load_test:\n",
        "  titanic_load_test[elem_test] = (pd.Categorical(titanic_load_test[elem_test])).codes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGh_SGY0MWF6",
        "colab_type": "code",
        "outputId": "ba1bd168-05fa-4d37-ec63-703dfc4c6a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Stampa delle prima 5 righe del dataset di train\n",
        "titanic_load_train.head()"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>523</td>\n",
              "      <td>18</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>596</td>\n",
              "      <td>207</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>669</td>\n",
              "      <td>41</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>189</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>472</td>\n",
              "      <td>43</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  Sex  ...  Ticket  Fare  Cabin  Embarked\n",
              "0            0         0       2    1  ...     523    18     -1         2\n",
              "1            1         1       0    0  ...     596   207     81         0\n",
              "2            2         1       2    0  ...     669    41     -1         2\n",
              "3            3         1       0    0  ...      49   189     55         2\n",
              "4            4         0       2    1  ...     472    43     -1         2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgeJkU0CPaSM",
        "colab_type": "code",
        "outputId": "30dc0595-f078-4b00-ea26-5ce5069eb1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Stampa delle prima 5 righe del dataset di test\n",
        "titanic_load_test.head()"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>24</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>41</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>147</td>\n",
              "      <td>34</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138</td>\n",
              "      <td>46</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked\n",
              "0            0       2    1   44      0      0     152    24     -1         1\n",
              "1            1       2    0   60      1      0     221     5     -1         2\n",
              "2            2       1    1   74      0      0      73    41     -1         1\n",
              "3            3       2    1   34      0      0     147    34     -1         2\n",
              "4            4       2    0   27      1      1     138    46     -1         2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0i_G4xHMfkl",
        "colab_type": "text"
      },
      "source": [
        "### Ripartizione del Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AdRqdIPZL-1",
        "colab_type": "text"
      },
      "source": [
        "Si esegue lo Split dei dataset per ricavare i dati di test e di valutazione: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIuoLXQNMjiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dividiamo il train set in due parti così da poter addestrare la rete:\n",
        "# y che contiene solo la colonna 'Survived' che consiste nella soluzione al problema\n",
        "# X che contiene tutte le altre colonne.\n",
        "y = titanic_load_train.Survived\n",
        "X = titanic_load_train.drop(labels=['Survived'], axis=1)\n",
        "\n",
        "# I Dati vengono, a loro volta, divisi in altre due parti: una per\n",
        "# l'addestramento e una per la valutazione della rete.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "# I dati vengono poi memorizzati dentro un Dataset di Tensorflow per sfruttarli\n",
        "# per l'addestramento. Questa stessa operazione viene poi fatta anche per il\n",
        "# test set e per l'evaluetion set.\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))).shuffle(len(X_train)).batch(1)\n",
        "val_dataset = (tf.data.Dataset.from_tensor_slices((X_val.values, y_val.values))).shuffle(len(X_val)).batch(1)\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(titanic_load_test.values)).batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcDn3ZnTqpY",
        "colab_type": "text"
      },
      "source": [
        "## La rete neurale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DwEsIQ_ZaDs",
        "colab_type": "text"
      },
      "source": [
        "Il modello utilizzato è formato da 3 layer totalmente connessi e viene utilizzato come algoritmo di ottimizzazione l'adam:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzlzXYxtRURi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_inputs = X_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqaMTc11TvG3",
        "colab_type": "code",
        "outputId": "edc14825-ad12-4b3b-c029-0cc86cce2b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "  tf.keras.layers.Dense(32, input_dim=num_inputs, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_70 (Dense)             (None, 32)                352       \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,441\n",
            "Trainable params: 1,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfURHtD1WVug",
        "colab_type": "text"
      },
      "source": [
        "## Addestramento della rete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf32IC7vZex1",
        "colab_type": "text"
      },
      "source": [
        "Ora è il momento di addestrare il modello tramite i dati di train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mIN4eC_UR8Z",
        "colab_type": "code",
        "outputId": "9ce88c14-e77e-4c03-8cbe-ab8c82f2bedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Addestramento della rete neurale\n",
        "model.fit(train_dataset, epochs=300)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 3.4845 - accuracy: 0.5758\n",
            "Epoch 2/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 2.0343 - accuracy: 0.6292\n",
            "Epoch 3/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.6810 - accuracy: 0.6503\n",
            "Epoch 4/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.4431 - accuracy: 0.6713\n",
            "Epoch 5/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.2063 - accuracy: 0.6699\n",
            "Epoch 6/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.3497 - accuracy: 0.6559\n",
            "Epoch 7/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.0675 - accuracy: 0.6868\n",
            "Epoch 8/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.9762 - accuracy: 0.6756\n",
            "Epoch 9/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 1.1465 - accuracy: 0.6728\n",
            "Epoch 10/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.8720 - accuracy: 0.6952\n",
            "Epoch 11/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.8738 - accuracy: 0.6756\n",
            "Epoch 12/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.7838 - accuracy: 0.7008\n",
            "Epoch 13/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.9377 - accuracy: 0.6587\n",
            "Epoch 14/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.6762 - accuracy: 0.6966\n",
            "Epoch 15/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.7205\n",
            "Epoch 16/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.7202 - accuracy: 0.7008\n",
            "Epoch 17/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.6897 - accuracy: 0.6826\n",
            "Epoch 18/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.6868\n",
            "Epoch 19/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.6281 - accuracy: 0.7065\n",
            "Epoch 20/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5872 - accuracy: 0.7247\n",
            "Epoch 21/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5724 - accuracy: 0.7331\n",
            "Epoch 22/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5891 - accuracy: 0.7107\n",
            "Epoch 23/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5999 - accuracy: 0.7191\n",
            "Epoch 24/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5750 - accuracy: 0.7317\n",
            "Epoch 25/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7346\n",
            "Epoch 26/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7261\n",
            "Epoch 27/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7205\n",
            "Epoch 28/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7177\n",
            "Epoch 29/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7163\n",
            "Epoch 30/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7247\n",
            "Epoch 31/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7275\n",
            "Epoch 32/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5295 - accuracy: 0.7416\n",
            "Epoch 33/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5568 - accuracy: 0.7219\n",
            "Epoch 34/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5238 - accuracy: 0.7346\n",
            "Epoch 35/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7612\n",
            "Epoch 36/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7388\n",
            "Epoch 37/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7486\n",
            "Epoch 38/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5242 - accuracy: 0.7472\n",
            "Epoch 39/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5227 - accuracy: 0.7528\n",
            "Epoch 40/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.7500\n",
            "Epoch 41/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5061 - accuracy: 0.7416\n",
            "Epoch 42/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4897 - accuracy: 0.7640\n",
            "Epoch 43/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5104 - accuracy: 0.7402\n",
            "Epoch 44/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.7514\n",
            "Epoch 45/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4939 - accuracy: 0.7528\n",
            "Epoch 46/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5133 - accuracy: 0.7626\n",
            "Epoch 47/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5035 - accuracy: 0.7458\n",
            "Epoch 48/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7514\n",
            "Epoch 49/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4757 - accuracy: 0.7612\n",
            "Epoch 50/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4974 - accuracy: 0.7458\n",
            "Epoch 51/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4833 - accuracy: 0.7654\n",
            "Epoch 52/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.7472\n",
            "Epoch 53/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4738 - accuracy: 0.7584\n",
            "Epoch 54/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4750 - accuracy: 0.7542\n",
            "Epoch 55/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4806 - accuracy: 0.7542\n",
            "Epoch 56/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4675 - accuracy: 0.7640\n",
            "Epoch 57/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.7598\n",
            "Epoch 58/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.7570\n",
            "Epoch 59/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.7640\n",
            "Epoch 60/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4571 - accuracy: 0.7683\n",
            "Epoch 61/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.7823\n",
            "Epoch 62/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.7612\n",
            "Epoch 63/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4478 - accuracy: 0.7739\n",
            "Epoch 64/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.7809\n",
            "Epoch 65/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4693 - accuracy: 0.7795\n",
            "Epoch 66/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.7640\n",
            "Epoch 67/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4608 - accuracy: 0.7711\n",
            "Epoch 68/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.7753\n",
            "Epoch 69/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4595 - accuracy: 0.7809\n",
            "Epoch 70/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4453 - accuracy: 0.7781\n",
            "Epoch 71/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.7669\n",
            "Epoch 72/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4288 - accuracy: 0.7978\n",
            "Epoch 73/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4556 - accuracy: 0.7767\n",
            "Epoch 74/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4385 - accuracy: 0.7767\n",
            "Epoch 75/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4281 - accuracy: 0.7823\n",
            "Epoch 76/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4229 - accuracy: 0.7935\n",
            "Epoch 77/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.7992\n",
            "Epoch 78/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4294 - accuracy: 0.7992\n",
            "Epoch 79/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.7893\n",
            "Epoch 80/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4317 - accuracy: 0.7809\n",
            "Epoch 81/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4422 - accuracy: 0.7907\n",
            "Epoch 82/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4596 - accuracy: 0.7697\n",
            "Epoch 83/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4389 - accuracy: 0.7921\n",
            "Epoch 84/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4314 - accuracy: 0.7823\n",
            "Epoch 85/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4393 - accuracy: 0.7907\n",
            "Epoch 86/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4261 - accuracy: 0.8048\n",
            "Epoch 87/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4170 - accuracy: 0.7865\n",
            "Epoch 88/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4254 - accuracy: 0.7865\n",
            "Epoch 89/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.7893\n",
            "Epoch 90/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.7949\n",
            "Epoch 91/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4279 - accuracy: 0.8006\n",
            "Epoch 92/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4299 - accuracy: 0.7935\n",
            "Epoch 93/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4366 - accuracy: 0.7795\n",
            "Epoch 94/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4221 - accuracy: 0.7963\n",
            "Epoch 95/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4325 - accuracy: 0.7739\n",
            "Epoch 96/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.7935\n",
            "Epoch 97/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.7921\n",
            "Epoch 98/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4213 - accuracy: 0.7963\n",
            "Epoch 99/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8020\n",
            "Epoch 100/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.7935\n",
            "Epoch 101/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4119 - accuracy: 0.7907\n",
            "Epoch 102/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4184 - accuracy: 0.8062\n",
            "Epoch 103/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.7949\n",
            "Epoch 104/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4581 - accuracy: 0.7851\n",
            "Epoch 105/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8048\n",
            "Epoch 106/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3956 - accuracy: 0.8062\n",
            "Epoch 107/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4167 - accuracy: 0.8104\n",
            "Epoch 108/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4106 - accuracy: 0.7963\n",
            "Epoch 109/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8146\n",
            "Epoch 110/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4114 - accuracy: 0.8090\n",
            "Epoch 111/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3843 - accuracy: 0.8160\n",
            "Epoch 112/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8160\n",
            "Epoch 113/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3791 - accuracy: 0.8174\n",
            "Epoch 114/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4219 - accuracy: 0.8188\n",
            "Epoch 115/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3992 - accuracy: 0.8090\n",
            "Epoch 116/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8160\n",
            "Epoch 117/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8146\n",
            "Epoch 118/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8244\n",
            "Epoch 119/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4129 - accuracy: 0.8104\n",
            "Epoch 120/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8076\n",
            "Epoch 121/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3817 - accuracy: 0.8118\n",
            "Epoch 122/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4067 - accuracy: 0.8062\n",
            "Epoch 123/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8104\n",
            "Epoch 124/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4104 - accuracy: 0.8188\n",
            "Epoch 125/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3877 - accuracy: 0.8216\n",
            "Epoch 126/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4091 - accuracy: 0.8132\n",
            "Epoch 127/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8160\n",
            "Epoch 128/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8188\n",
            "Epoch 129/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8146\n",
            "Epoch 130/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3730 - accuracy: 0.8272\n",
            "Epoch 131/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3817 - accuracy: 0.8202\n",
            "Epoch 132/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3883 - accuracy: 0.8006\n",
            "Epoch 133/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3801 - accuracy: 0.8272\n",
            "Epoch 134/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8230\n",
            "Epoch 135/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3766 - accuracy: 0.8118\n",
            "Epoch 136/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8062\n",
            "Epoch 137/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.7978\n",
            "Epoch 138/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8216\n",
            "Epoch 139/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3850 - accuracy: 0.8258\n",
            "Epoch 140/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3761 - accuracy: 0.8104\n",
            "Epoch 141/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3774 - accuracy: 0.8062\n",
            "Epoch 142/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3826 - accuracy: 0.8132\n",
            "Epoch 143/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3730 - accuracy: 0.8287\n",
            "Epoch 144/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3970 - accuracy: 0.8118\n",
            "Epoch 145/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3776 - accuracy: 0.8244\n",
            "Epoch 146/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8160\n",
            "Epoch 147/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8006\n",
            "Epoch 148/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8174\n",
            "Epoch 149/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.8090\n",
            "Epoch 150/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8118\n",
            "Epoch 151/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3525 - accuracy: 0.8258\n",
            "Epoch 152/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.8258\n",
            "Epoch 153/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8188\n",
            "Epoch 154/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8160\n",
            "Epoch 155/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3749 - accuracy: 0.8230\n",
            "Epoch 156/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3638 - accuracy: 0.8160\n",
            "Epoch 157/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3847 - accuracy: 0.8090\n",
            "Epoch 158/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8174\n",
            "Epoch 159/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8371\n",
            "Epoch 160/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8174\n",
            "Epoch 161/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8230\n",
            "Epoch 162/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3712 - accuracy: 0.8385\n",
            "Epoch 163/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3671 - accuracy: 0.8315\n",
            "Epoch 164/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8090\n",
            "Epoch 165/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3646 - accuracy: 0.8160\n",
            "Epoch 166/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3752 - accuracy: 0.8315\n",
            "Epoch 167/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8146\n",
            "Epoch 168/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.8244\n",
            "Epoch 169/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3726 - accuracy: 0.8301\n",
            "Epoch 170/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3723 - accuracy: 0.8287\n",
            "Epoch 171/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3618 - accuracy: 0.8202\n",
            "Epoch 172/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3467 - accuracy: 0.8329\n",
            "Epoch 173/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3613 - accuracy: 0.8174\n",
            "Epoch 174/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8230\n",
            "Epoch 175/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3756 - accuracy: 0.8244\n",
            "Epoch 176/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.7978\n",
            "Epoch 177/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3781 - accuracy: 0.8118\n",
            "Epoch 178/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3733 - accuracy: 0.8202\n",
            "Epoch 179/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8258\n",
            "Epoch 180/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3577 - accuracy: 0.8188\n",
            "Epoch 181/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3833 - accuracy: 0.8202\n",
            "Epoch 182/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3774 - accuracy: 0.8315\n",
            "Epoch 183/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3682 - accuracy: 0.8272\n",
            "Epoch 184/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3587 - accuracy: 0.8301\n",
            "Epoch 185/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3454 - accuracy: 0.8216\n",
            "Epoch 186/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3637 - accuracy: 0.8146\n",
            "Epoch 187/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3768 - accuracy: 0.8272\n",
            "Epoch 188/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3732 - accuracy: 0.8104\n",
            "Epoch 189/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3731 - accuracy: 0.8090\n",
            "Epoch 190/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3741 - accuracy: 0.8216\n",
            "Epoch 191/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3850 - accuracy: 0.8188\n",
            "Epoch 192/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4124 - accuracy: 0.8385\n",
            "Epoch 193/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3475 - accuracy: 0.8385\n",
            "Epoch 194/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8301\n",
            "Epoch 195/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3492 - accuracy: 0.8258\n",
            "Epoch 196/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8287\n",
            "Epoch 197/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3737 - accuracy: 0.8090\n",
            "Epoch 198/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3822 - accuracy: 0.8202\n",
            "Epoch 199/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8329\n",
            "Epoch 200/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8287\n",
            "Epoch 201/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.8343\n",
            "Epoch 202/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4453 - accuracy: 0.8076\n",
            "Epoch 203/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3609 - accuracy: 0.8244\n",
            "Epoch 204/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8329\n",
            "Epoch 205/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3492 - accuracy: 0.8230\n",
            "Epoch 206/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3759 - accuracy: 0.8272\n",
            "Epoch 207/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8244\n",
            "Epoch 208/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8272\n",
            "Epoch 209/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8343\n",
            "Epoch 210/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8385\n",
            "Epoch 211/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.8315\n",
            "Epoch 212/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8343\n",
            "Epoch 213/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8272\n",
            "Epoch 214/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3754 - accuracy: 0.8230\n",
            "Epoch 215/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3529 - accuracy: 0.8385\n",
            "Epoch 216/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8258\n",
            "Epoch 217/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8301\n",
            "Epoch 218/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3622 - accuracy: 0.8301\n",
            "Epoch 219/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3453 - accuracy: 0.8174\n",
            "Epoch 220/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8287\n",
            "Epoch 221/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3550 - accuracy: 0.8315\n",
            "Epoch 222/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3704 - accuracy: 0.8118\n",
            "Epoch 223/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8287\n",
            "Epoch 224/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8244\n",
            "Epoch 225/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3618 - accuracy: 0.8287\n",
            "Epoch 226/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3565 - accuracy: 0.8258\n",
            "Epoch 227/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8272\n",
            "Epoch 228/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8301\n",
            "Epoch 229/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3571 - accuracy: 0.8202\n",
            "Epoch 230/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3664 - accuracy: 0.8399\n",
            "Epoch 231/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8413\n",
            "Epoch 232/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3591 - accuracy: 0.8244\n",
            "Epoch 233/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4188 - accuracy: 0.8287\n",
            "Epoch 234/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8287\n",
            "Epoch 235/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8427\n",
            "Epoch 236/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3485 - accuracy: 0.8230\n",
            "Epoch 237/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.8357\n",
            "Epoch 238/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3546 - accuracy: 0.8315\n",
            "Epoch 239/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3350 - accuracy: 0.8343\n",
            "Epoch 240/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3529 - accuracy: 0.8399\n",
            "Epoch 241/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3139 - accuracy: 0.8539\n",
            "Epoch 242/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8357\n",
            "Epoch 243/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8399\n",
            "Epoch 244/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8329\n",
            "Epoch 245/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3548 - accuracy: 0.8357\n",
            "Epoch 246/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3172 - accuracy: 0.8427\n",
            "Epoch 247/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8343\n",
            "Epoch 248/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8315\n",
            "Epoch 249/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8497\n",
            "Epoch 250/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3173 - accuracy: 0.8455\n",
            "Epoch 251/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8469\n",
            "Epoch 252/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3589 - accuracy: 0.8413\n",
            "Epoch 253/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3247 - accuracy: 0.8413\n",
            "Epoch 254/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8427\n",
            "Epoch 255/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4459 - accuracy: 0.8202\n",
            "Epoch 256/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8371\n",
            "Epoch 257/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3495 - accuracy: 0.8343\n",
            "Epoch 258/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8497\n",
            "Epoch 259/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8441\n",
            "Epoch 260/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3723 - accuracy: 0.8301\n",
            "Epoch 261/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3244 - accuracy: 0.8441\n",
            "Epoch 262/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3080 - accuracy: 0.8441\n",
            "Epoch 263/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8553\n",
            "Epoch 264/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.8567\n",
            "Epoch 265/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8413\n",
            "Epoch 266/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3491 - accuracy: 0.8413\n",
            "Epoch 267/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3170 - accuracy: 0.8469\n",
            "Epoch 268/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3357 - accuracy: 0.8371\n",
            "Epoch 269/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3688 - accuracy: 0.8385\n",
            "Epoch 270/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3497 - accuracy: 0.8427\n",
            "Epoch 271/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8329\n",
            "Epoch 272/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8202\n",
            "Epoch 273/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8287\n",
            "Epoch 274/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.8413\n",
            "Epoch 275/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8329\n",
            "Epoch 276/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3603 - accuracy: 0.8385\n",
            "Epoch 277/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8455\n",
            "Epoch 278/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8385\n",
            "Epoch 279/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3073 - accuracy: 0.8483\n",
            "Epoch 280/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8399\n",
            "Epoch 281/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.8413\n",
            "Epoch 282/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.8511\n",
            "Epoch 283/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3524 - accuracy: 0.8329\n",
            "Epoch 284/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3482 - accuracy: 0.8371\n",
            "Epoch 285/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3480 - accuracy: 0.8441\n",
            "Epoch 286/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3132 - accuracy: 0.8371\n",
            "Epoch 287/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3163 - accuracy: 0.8581\n",
            "Epoch 288/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3233 - accuracy: 0.8539\n",
            "Epoch 289/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3601 - accuracy: 0.8301\n",
            "Epoch 290/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8469\n",
            "Epoch 291/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8343\n",
            "Epoch 292/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.8301\n",
            "Epoch 293/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3694 - accuracy: 0.8483\n",
            "Epoch 294/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3684 - accuracy: 0.8258\n",
            "Epoch 295/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8553\n",
            "Epoch 296/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3188 - accuracy: 0.8497\n",
            "Epoch 297/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3214 - accuracy: 0.8539\n",
            "Epoch 298/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3144 - accuracy: 0.8553\n",
            "Epoch 299/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.8553\n",
            "Epoch 300/300\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd8729eef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKtxZ2HYWZk0",
        "colab_type": "text"
      },
      "source": [
        "## Valutazione della rete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1cCv3LNZhrt",
        "colab_type": "text"
      },
      "source": [
        "Eseguiamo la valutazione del modello:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Jxqd-lUmaV",
        "colab_type": "code",
        "outputId": "c870b889-d04b-42ab-ede3-8bf1da085989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Valutazione del modello\n",
        "val_loss, val_acc = model.evaluate(val_dataset)\n",
        "print(\"\\nTest accuracy: {:.2f} ({:.2%})\".format(val_acc, val_acc))"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "179/179 [==============================] - 0s 2ms/step - loss: 1.1364 - accuracy: 0.7709\n",
            "\n",
            "Test accuracy: 0.77 (77.09%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwWviCzhZwfQ",
        "colab_type": "text"
      },
      "source": [
        "## Previsione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJOjP9SHZ1ZQ",
        "colab_type": "text"
      },
      "source": [
        "Ora è il momento di predire i valori del dataset di test tramite l'addestramento appena effettuato:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACgBSfpKZyRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predizione dei dati tramite il modello\n",
        "predictions = model.predict(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6Vj5_7aRLd",
        "colab_type": "text"
      },
      "source": [
        "Effettuiamo una breve stampa dei valori ottenuti tramite `predict` e degli effettivi valori riferimento. Qui vengono mostrato anche il valore di accuratezza della predizione:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBmIIEvzhfrY",
        "colab_type": "code",
        "outputId": "35998db0-7ad1-4f08-8006-a03ccc6c8655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r=0\n",
        "f=0\n",
        "\n",
        "# Eseguiamo la stampa dei valori 'predictions' ottenuti tramite\n",
        "# la predizione con la rete neurale e delle etichette\n",
        "# reali 'titanic_load_test_label['Survived']'.\n",
        "print(\"passegerID \\t Prediction \\t\\t\\t Label \\t Description\\n\")\n",
        "for pid, prediction, label in zip(titanic_load_test['PassengerId'], tf.sigmoid(predictions).numpy(), titanic_load_test_label['Survived']):\n",
        "  message = \"{} \\t\\t Predicted survival: {:.2%} \\t {}\".format(pid, prediction[0], label)\n",
        "  if tf.round(prediction)==label:\n",
        "    r+=1\n",
        "  else:\n",
        "    message += \" \\t PREDIZIONE ERRATA\"\n",
        "    f+=1\n",
        "  print(message)\n",
        "\n",
        "print(\"\\n - Totale predizioni corrette: {}\\n - Totale predizioni errate: {}\".format(r,f))"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "passegerID \t Prediction \t\t\t Label \t Description\n",
            "\n",
            "0 \t\t Predicted survival: 0.32% \t 0\n",
            "1 \t\t Predicted survival: 2.92% \t 1 \t PREDIZIONE ERRATA\n",
            "2 \t\t Predicted survival: 0.00% \t 0\n",
            "3 \t\t Predicted survival: 0.02% \t 0\n",
            "4 \t\t Predicted survival: 0.18% \t 1 \t PREDIZIONE ERRATA\n",
            "5 \t\t Predicted survival: 0.00% \t 0\n",
            "6 \t\t Predicted survival: 20.60% \t 1 \t PREDIZIONE ERRATA\n",
            "7 \t\t Predicted survival: 0.00% \t 0\n",
            "8 \t\t Predicted survival: 48.53% \t 1 \t PREDIZIONE ERRATA\n",
            "9 \t\t Predicted survival: 0.00% \t 0\n",
            "10 \t\t Predicted survival: 0.40% \t 0\n",
            "11 \t\t Predicted survival: 0.00% \t 0\n",
            "12 \t\t Predicted survival: 100.00% \t 1\n",
            "13 \t\t Predicted survival: 0.00% \t 0\n",
            "14 \t\t Predicted survival: 0.35% \t 1 \t PREDIZIONE ERRATA\n",
            "15 \t\t Predicted survival: 0.01% \t 1 \t PREDIZIONE ERRATA\n",
            "16 \t\t Predicted survival: 0.00% \t 0\n",
            "17 \t\t Predicted survival: 0.03% \t 0\n",
            "18 \t\t Predicted survival: 0.01% \t 1 \t PREDIZIONE ERRATA\n",
            "19 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "20 \t\t Predicted survival: 0.00% \t 0\n",
            "21 \t\t Predicted survival: 0.00% \t 0\n",
            "22 \t\t Predicted survival: 99.51% \t 1\n",
            "23 \t\t Predicted survival: 0.00% \t 0\n",
            "24 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "25 \t\t Predicted survival: 0.00% \t 0\n",
            "26 \t\t Predicted survival: 100.00% \t 1\n",
            "27 \t\t Predicted survival: 0.02% \t 0\n",
            "28 \t\t Predicted survival: 0.00% \t 0\n",
            "29 \t\t Predicted survival: 0.00% \t 0\n",
            "30 \t\t Predicted survival: 0.00% \t 0\n",
            "31 \t\t Predicted survival: 0.00% \t 0\n",
            "32 \t\t Predicted survival: 3.91% \t 1 \t PREDIZIONE ERRATA\n",
            "33 \t\t Predicted survival: 18.23% \t 1 \t PREDIZIONE ERRATA\n",
            "34 \t\t Predicted survival: 0.00% \t 0\n",
            "35 \t\t Predicted survival: 0.11% \t 0\n",
            "36 \t\t Predicted survival: 71.69% \t 1\n",
            "37 \t\t Predicted survival: 30.52% \t 1 \t PREDIZIONE ERRATA\n",
            "38 \t\t Predicted survival: 0.10% \t 0\n",
            "39 \t\t Predicted survival: 10.67% \t 0\n",
            "40 \t\t Predicted survival: 0.00% \t 0\n",
            "41 \t\t Predicted survival: 85.89% \t 0 \t PREDIZIONE ERRATA\n",
            "42 \t\t Predicted survival: 0.00% \t 0\n",
            "43 \t\t Predicted survival: 0.11% \t 1 \t PREDIZIONE ERRATA\n",
            "44 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "45 \t\t Predicted survival: 0.61% \t 0\n",
            "46 \t\t Predicted survival: 0.00% \t 0\n",
            "47 \t\t Predicted survival: 7.35% \t 0\n",
            "48 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "49 \t\t Predicted survival: 9.37% \t 1 \t PREDIZIONE ERRATA\n",
            "50 \t\t Predicted survival: 0.00% \t 0\n",
            "51 \t\t Predicted survival: 0.80% \t 0\n",
            "52 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "53 \t\t Predicted survival: 0.03% \t 1 \t PREDIZIONE ERRATA\n",
            "54 \t\t Predicted survival: 0.46% \t 0\n",
            "55 \t\t Predicted survival: 0.00% \t 0\n",
            "56 \t\t Predicted survival: 0.01% \t 0\n",
            "57 \t\t Predicted survival: 0.04% \t 0\n",
            "58 \t\t Predicted survival: 15.89% \t 0\n",
            "59 \t\t Predicted survival: 0.50% \t 1 \t PREDIZIONE ERRATA\n",
            "60 \t\t Predicted survival: 14.81% \t 0\n",
            "61 \t\t Predicted survival: 0.00% \t 0\n",
            "62 \t\t Predicted survival: 2.85% \t 0\n",
            "63 \t\t Predicted survival: 60.33% \t 1\n",
            "64 \t\t Predicted survival: 0.00% \t 0\n",
            "65 \t\t Predicted survival: 81.90% \t 1\n",
            "66 \t\t Predicted survival: 64.64% \t 1\n",
            "67 \t\t Predicted survival: 0.00% \t 0\n",
            "68 \t\t Predicted survival: 0.01% \t 0\n",
            "69 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "70 \t\t Predicted survival: 39.03% \t 1 \t PREDIZIONE ERRATA\n",
            "71 \t\t Predicted survival: 3.46% \t 0\n",
            "72 \t\t Predicted survival: 6.81% \t 1 \t PREDIZIONE ERRATA\n",
            "73 \t\t Predicted survival: 0.00% \t 0\n",
            "74 \t\t Predicted survival: 99.99% \t 1\n",
            "75 \t\t Predicted survival: 0.21% \t 0\n",
            "76 \t\t Predicted survival: 24.22% \t 0\n",
            "77 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "78 \t\t Predicted survival: 0.02% \t 0\n",
            "79 \t\t Predicted survival: 67.30% \t 1\n",
            "80 \t\t Predicted survival: 0.01% \t 0\n",
            "81 \t\t Predicted survival: 0.00% \t 0\n",
            "82 \t\t Predicted survival: 0.00% \t 0\n",
            "83 \t\t Predicted survival: 25.16% \t 0\n",
            "84 \t\t Predicted survival: 0.88% \t 0\n",
            "85 \t\t Predicted survival: 1.55% \t 0\n",
            "86 \t\t Predicted survival: 31.37% \t 1 \t PREDIZIONE ERRATA\n",
            "87 \t\t Predicted survival: 67.90% \t 1\n",
            "88 \t\t Predicted survival: 53.39% \t 1\n",
            "89 \t\t Predicted survival: 0.00% \t 0\n",
            "90 \t\t Predicted survival: 44.94% \t 1 \t PREDIZIONE ERRATA\n",
            "91 \t\t Predicted survival: 4.53% \t 0\n",
            "92 \t\t Predicted survival: 0.63% \t 1 \t PREDIZIONE ERRATA\n",
            "93 \t\t Predicted survival: 27.37% \t 0\n",
            "94 \t\t Predicted survival: 0.11% \t 0\n",
            "95 \t\t Predicted survival: 0.97% \t 0\n",
            "96 \t\t Predicted survival: 0.02% \t 1 \t PREDIZIONE ERRATA\n",
            "97 \t\t Predicted survival: 1.44% \t 0\n",
            "98 \t\t Predicted survival: 59.60% \t 1\n",
            "99 \t\t Predicted survival: 1.43% \t 0\n",
            "100 \t\t Predicted survival: 100.00% \t 1\n",
            "101 \t\t Predicted survival: 0.00% \t 0\n",
            "102 \t\t Predicted survival: 13.67% \t 0\n",
            "103 \t\t Predicted survival: 0.08% \t 0\n",
            "104 \t\t Predicted survival: 16.17% \t 1 \t PREDIZIONE ERRATA\n",
            "105 \t\t Predicted survival: 15.90% \t 0\n",
            "106 \t\t Predicted survival: 0.41% \t 0\n",
            "107 \t\t Predicted survival: 13.31% \t 0\n",
            "108 \t\t Predicted survival: 21.86% \t 0\n",
            "109 \t\t Predicted survival: 0.22% \t 0\n",
            "110 \t\t Predicted survival: 0.00% \t 0\n",
            "111 \t\t Predicted survival: 62.51% \t 1\n",
            "112 \t\t Predicted survival: 36.53% \t 1 \t PREDIZIONE ERRATA\n",
            "113 \t\t Predicted survival: 48.29% \t 1 \t PREDIZIONE ERRATA\n",
            "114 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "115 \t\t Predicted survival: 0.07% \t 0\n",
            "116 \t\t Predicted survival: 0.00% \t 0\n",
            "117 \t\t Predicted survival: 1.84% \t 1 \t PREDIZIONE ERRATA\n",
            "118 \t\t Predicted survival: 1.68% \t 0\n",
            "119 \t\t Predicted survival: 7.61% \t 1 \t PREDIZIONE ERRATA\n",
            "120 \t\t Predicted survival: 61.17% \t 1\n",
            "121 \t\t Predicted survival: 1.90% \t 0\n",
            "122 \t\t Predicted survival: 100.00% \t 1\n",
            "123 \t\t Predicted survival: 1.90% \t 0\n",
            "124 \t\t Predicted survival: 8.15% \t 0\n",
            "125 \t\t Predicted survival: 64.64% \t 1\n",
            "126 \t\t Predicted survival: 1.78% \t 0\n",
            "127 \t\t Predicted survival: 64.49% \t 1\n",
            "128 \t\t Predicted survival: 0.00% \t 0\n",
            "129 \t\t Predicted survival: 0.10% \t 0\n",
            "130 \t\t Predicted survival: 10.46% \t 0\n",
            "131 \t\t Predicted survival: 0.00% \t 0\n",
            "132 \t\t Predicted survival: 39.47% \t 1 \t PREDIZIONE ERRATA\n",
            "133 \t\t Predicted survival: 0.00% \t 0\n",
            "134 \t\t Predicted survival: 0.00% \t 0\n",
            "135 \t\t Predicted survival: 1.43% \t 0\n",
            "136 \t\t Predicted survival: 0.02% \t 0\n",
            "137 \t\t Predicted survival: 0.13% \t 0\n",
            "138 \t\t Predicted survival: 77.51% \t 1\n",
            "139 \t\t Predicted survival: 0.00% \t 0\n",
            "140 \t\t Predicted survival: 0.91% \t 1 \t PREDIZIONE ERRATA\n",
            "141 \t\t Predicted survival: 100.00% \t 1\n",
            "142 \t\t Predicted survival: 0.00% \t 0\n",
            "143 \t\t Predicted survival: 3.56% \t 0\n",
            "144 \t\t Predicted survival: 2.56% \t 0\n",
            "145 \t\t Predicted survival: 0.00% \t 0\n",
            "146 \t\t Predicted survival: 100.00% \t 0 \t PREDIZIONE ERRATA\n",
            "147 \t\t Predicted survival: 37.90% \t 0\n",
            "148 \t\t Predicted survival: 12.20% \t 0\n",
            "149 \t\t Predicted survival: 0.01% \t 0\n",
            "150 \t\t Predicted survival: 99.97% \t 1\n",
            "151 \t\t Predicted survival: 26.89% \t 0\n",
            "152 \t\t Predicted survival: 0.00% \t 0\n",
            "153 \t\t Predicted survival: 15.92% \t 1 \t PREDIZIONE ERRATA\n",
            "154 \t\t Predicted survival: 0.00% \t 0\n",
            "155 \t\t Predicted survival: 28.06% \t 0\n",
            "156 \t\t Predicted survival: 100.00% \t 1\n",
            "157 \t\t Predicted survival: 46.91% \t 1 \t PREDIZIONE ERRATA\n",
            "158 \t\t Predicted survival: 0.00% \t 0\n",
            "159 \t\t Predicted survival: 74.50% \t 1\n",
            "160 \t\t Predicted survival: 48.44% \t 1 \t PREDIZIONE ERRATA\n",
            "161 \t\t Predicted survival: 0.04% \t 0\n",
            "162 \t\t Predicted survival: 63.93% \t 1\n",
            "163 \t\t Predicted survival: 0.00% \t 0\n",
            "164 \t\t Predicted survival: 0.00% \t 0\n",
            "165 \t\t Predicted survival: 19.53% \t 1 \t PREDIZIONE ERRATA\n",
            "166 \t\t Predicted survival: 0.01% \t 0\n",
            "167 \t\t Predicted survival: 58.57% \t 0 \t PREDIZIONE ERRATA\n",
            "168 \t\t Predicted survival: 95.84% \t 1\n",
            "169 \t\t Predicted survival: 61.99% \t 1\n",
            "170 \t\t Predicted survival: 0.00% \t 0\n",
            "171 \t\t Predicted survival: 0.01% \t 0\n",
            "172 \t\t Predicted survival: 0.11% \t 0\n",
            "173 \t\t Predicted survival: 0.00% \t 0\n",
            "174 \t\t Predicted survival: 0.00% \t 0\n",
            "175 \t\t Predicted survival: 84.59% \t 1\n",
            "176 \t\t Predicted survival: 64.64% \t 1\n",
            "177 \t\t Predicted survival: 98.38% \t 0 \t PREDIZIONE ERRATA\n",
            "178 \t\t Predicted survival: 0.24% \t 1 \t PREDIZIONE ERRATA\n",
            "179 \t\t Predicted survival: 0.35% \t 1 \t PREDIZIONE ERRATA\n",
            "180 \t\t Predicted survival: 1.17% \t 0\n",
            "181 \t\t Predicted survival: 0.12% \t 0\n",
            "182 \t\t Predicted survival: 97.08% \t 1\n",
            "183 \t\t Predicted survival: 1.80% \t 0\n",
            "184 \t\t Predicted survival: 99.96% \t 1\n",
            "185 \t\t Predicted survival: 4.24% \t 0\n",
            "186 \t\t Predicted survival: 70.92% \t 1\n",
            "187 \t\t Predicted survival: 8.52% \t 0\n",
            "188 \t\t Predicted survival: 5.63% \t 1 \t PREDIZIONE ERRATA\n",
            "189 \t\t Predicted survival: 0.03% \t 0\n",
            "190 \t\t Predicted survival: 16.90% \t 0\n",
            "191 \t\t Predicted survival: 1.27% \t 0\n",
            "192 \t\t Predicted survival: 14.98% \t 0\n",
            "193 \t\t Predicted survival: 0.00% \t 0\n",
            "194 \t\t Predicted survival: 9.63% \t 0\n",
            "195 \t\t Predicted survival: 0.00% \t 0\n",
            "196 \t\t Predicted survival: 99.97% \t 0 \t PREDIZIONE ERRATA\n",
            "197 \t\t Predicted survival: 46.43% \t 1 \t PREDIZIONE ERRATA\n",
            "198 \t\t Predicted survival: 24.25% \t 0\n",
            "199 \t\t Predicted survival: 55.56% \t 1\n",
            "200 \t\t Predicted survival: 65.15% \t 1\n",
            "201 \t\t Predicted survival: 15.48% \t 0\n",
            "202 \t\t Predicted survival: 0.00% \t 0\n",
            "203 \t\t Predicted survival: 60.09% \t 1\n",
            "204 \t\t Predicted survival: 24.00% \t 0\n",
            "205 \t\t Predicted survival: 40.89% \t 0\n",
            "206 \t\t Predicted survival: 37.94% \t 1 \t PREDIZIONE ERRATA\n",
            "207 \t\t Predicted survival: 0.03% \t 0\n",
            "208 \t\t Predicted survival: 84.92% \t 1\n",
            "209 \t\t Predicted survival: 0.24% \t 0\n",
            "210 \t\t Predicted survival: 20.82% \t 0\n",
            "211 \t\t Predicted survival: 0.00% \t 0\n",
            "212 \t\t Predicted survival: 52.51% \t 0 \t PREDIZIONE ERRATA\n",
            "213 \t\t Predicted survival: 74.04% \t 1\n",
            "214 \t\t Predicted survival: 0.00% \t 1 \t PREDIZIONE ERRATA\n",
            "215 \t\t Predicted survival: 99.98% \t 0 \t PREDIZIONE ERRATA\n",
            "216 \t\t Predicted survival: 55.45% \t 1\n",
            "217 \t\t Predicted survival: 0.00% \t 0\n",
            "218 \t\t Predicted survival: 100.00% \t 1\n",
            "219 \t\t Predicted survival: 6.64% \t 0\n",
            "220 \t\t Predicted survival: 70.32% \t 1\n",
            "221 \t\t Predicted survival: 0.08% \t 0\n",
            "222 \t\t Predicted survival: 87.32% \t 1\n",
            "223 \t\t Predicted survival: 0.72% \t 0\n",
            "224 \t\t Predicted survival: 53.45% \t 1\n",
            "225 \t\t Predicted survival: 66.03% \t 1\n",
            "226 \t\t Predicted survival: 0.36% \t 0\n",
            "227 \t\t Predicted survival: 33.69% \t 1 \t PREDIZIONE ERRATA\n",
            "228 \t\t Predicted survival: 1.81% \t 0\n",
            "229 \t\t Predicted survival: 2.53% \t 0\n",
            "230 \t\t Predicted survival: 17.59% \t 0\n",
            "231 \t\t Predicted survival: 99.04% \t 1\n",
            "232 \t\t Predicted survival: 0.00% \t 0\n",
            "233 \t\t Predicted survival: 8.86% \t 0\n",
            "234 \t\t Predicted survival: 0.94% \t 0\n",
            "235 \t\t Predicted survival: 1.49% \t 0\n",
            "236 \t\t Predicted survival: 0.00% \t 0\n",
            "237 \t\t Predicted survival: 0.01% \t 0\n",
            "238 \t\t Predicted survival: 49.59% \t 1 \t PREDIZIONE ERRATA\n",
            "239 \t\t Predicted survival: 99.14% \t 1\n",
            "240 \t\t Predicted survival: 100.00% \t 1\n",
            "241 \t\t Predicted survival: 92.47% \t 1\n",
            "242 \t\t Predicted survival: 10.06% \t 0\n",
            "243 \t\t Predicted survival: 2.66% \t 0\n",
            "244 \t\t Predicted survival: 14.15% \t 0\n",
            "245 \t\t Predicted survival: 69.23% \t 0 \t PREDIZIONE ERRATA\n",
            "246 \t\t Predicted survival: 65.48% \t 1\n",
            "247 \t\t Predicted survival: 16.34% \t 0\n",
            "248 \t\t Predicted survival: 57.25% \t 1\n",
            "249 \t\t Predicted survival: 67.32% \t 1\n",
            "250 \t\t Predicted survival: 51.43% \t 1\n",
            "251 \t\t Predicted survival: 29.31% \t 0\n",
            "252 \t\t Predicted survival: 17.48% \t 0\n",
            "253 \t\t Predicted survival: 8.32% \t 0\n",
            "254 \t\t Predicted survival: 0.00% \t 0\n",
            "255 \t\t Predicted survival: 0.00% \t 0\n",
            "256 \t\t Predicted survival: 0.05% \t 0\n",
            "257 \t\t Predicted survival: 0.19% \t 0\n",
            "258 \t\t Predicted survival: 59.63% \t 1\n",
            "259 \t\t Predicted survival: 0.03% \t 0\n",
            "260 \t\t Predicted survival: 0.01% \t 0\n",
            "261 \t\t Predicted survival: 0.81% \t 0\n",
            "262 \t\t Predicted survival: 62.62% \t 1\n",
            "263 \t\t Predicted survival: 36.33% \t 1 \t PREDIZIONE ERRATA\n",
            "264 \t\t Predicted survival: 26.38% \t 0\n",
            "265 \t\t Predicted survival: 3.01% \t 0\n",
            "266 \t\t Predicted survival: 0.00% \t 0\n",
            "267 \t\t Predicted survival: 0.00% \t 0\n",
            "268 \t\t Predicted survival: 47.96% \t 1 \t PREDIZIONE ERRATA\n",
            "269 \t\t Predicted survival: 0.04% \t 0\n",
            "270 \t\t Predicted survival: 51.00% \t 0 \t PREDIZIONE ERRATA\n",
            "271 \t\t Predicted survival: 0.03% \t 0\n",
            "272 \t\t Predicted survival: 85.86% \t 1\n",
            "273 \t\t Predicted survival: 52.71% \t 1\n",
            "274 \t\t Predicted survival: 0.00% \t 0\n",
            "275 \t\t Predicted survival: 80.35% \t 1\n",
            "276 \t\t Predicted survival: 24.65% \t 0\n",
            "277 \t\t Predicted survival: 13.91% \t 0\n",
            "278 \t\t Predicted survival: 13.33% \t 0\n",
            "279 \t\t Predicted survival: 29.55% \t 0\n",
            "280 \t\t Predicted survival: 44.36% \t 1 \t PREDIZIONE ERRATA\n",
            "281 \t\t Predicted survival: 14.90% \t 0\n",
            "282 \t\t Predicted survival: 55.11% \t 1\n",
            "283 \t\t Predicted survival: 58.71% \t 1\n",
            "284 \t\t Predicted survival: 44.80% \t 1 \t PREDIZIONE ERRATA\n",
            "285 \t\t Predicted survival: 0.03% \t 0\n",
            "286 \t\t Predicted survival: 0.00% \t 0\n",
            "287 \t\t Predicted survival: 93.58% \t 0 \t PREDIZIONE ERRATA\n",
            "288 \t\t Predicted survival: 0.00% \t 0\n",
            "289 \t\t Predicted survival: 5.39% \t 0\n",
            "290 \t\t Predicted survival: 39.61% \t 0\n",
            "291 \t\t Predicted survival: 25.38% \t 1 \t PREDIZIONE ERRATA\n",
            "292 \t\t Predicted survival: 0.00% \t 0\n",
            "293 \t\t Predicted survival: 32.18% \t 0\n",
            "294 \t\t Predicted survival: 0.00% \t 0\n",
            "295 \t\t Predicted survival: 0.04% \t 0\n",
            "296 \t\t Predicted survival: 66.57% \t 1\n",
            "297 \t\t Predicted survival: 10.58% \t 0\n",
            "298 \t\t Predicted survival: 99.57% \t 0 \t PREDIZIONE ERRATA\n",
            "299 \t\t Predicted survival: 0.01% \t 0\n",
            "300 \t\t Predicted survival: 0.00% \t 0\n",
            "301 \t\t Predicted survival: 51.34% \t 0 \t PREDIZIONE ERRATA\n",
            "302 \t\t Predicted survival: 11.00% \t 0\n",
            "303 \t\t Predicted survival: 0.01% \t 0\n",
            "304 \t\t Predicted survival: 53.28% \t 1\n",
            "305 \t\t Predicted survival: 38.54% \t 1 \t PREDIZIONE ERRATA\n",
            "306 \t\t Predicted survival: 98.06% \t 0 \t PREDIZIONE ERRATA\n",
            "307 \t\t Predicted survival: 13.08% \t 0\n",
            "308 \t\t Predicted survival: 99.45% \t 0 \t PREDIZIONE ERRATA\n",
            "309 \t\t Predicted survival: 5.75% \t 1 \t PREDIZIONE ERRATA\n",
            "310 \t\t Predicted survival: 0.30% \t 0\n",
            "311 \t\t Predicted survival: 0.01% \t 0\n",
            "312 \t\t Predicted survival: 0.00% \t 0\n",
            "313 \t\t Predicted survival: 7.04% \t 1 \t PREDIZIONE ERRATA\n",
            "314 \t\t Predicted survival: 99.71% \t 1\n",
            "315 \t\t Predicted survival: 58.71% \t 1\n",
            "316 \t\t Predicted survival: 3.37% \t 0\n",
            "317 \t\t Predicted survival: 19.24% \t 0\n",
            "318 \t\t Predicted survival: 0.05% \t 0\n",
            "319 \t\t Predicted survival: 13.27% \t 0\n",
            "320 \t\t Predicted survival: 0.01% \t 0\n",
            "321 \t\t Predicted survival: 0.00% \t 0\n",
            "322 \t\t Predicted survival: 0.01% \t 0\n",
            "323 \t\t Predicted survival: 58.48% \t 0 \t PREDIZIONE ERRATA\n",
            "324 \t\t Predicted survival: 94.84% \t 1\n",
            "325 \t\t Predicted survival: 0.27% \t 0\n",
            "326 \t\t Predicted survival: 96.85% \t 1\n",
            "327 \t\t Predicted survival: 31.43% \t 0\n",
            "328 \t\t Predicted survival: 29.75% \t 0\n",
            "329 \t\t Predicted survival: 26.00% \t 0\n",
            "330 \t\t Predicted survival: 53.45% \t 1\n",
            "331 \t\t Predicted survival: 31.14% \t 0\n",
            "332 \t\t Predicted survival: 0.00% \t 0\n",
            "333 \t\t Predicted survival: 53.99% \t 1\n",
            "334 \t\t Predicted survival: 0.02% \t 0\n",
            "335 \t\t Predicted survival: 30.76% \t 0\n",
            "336 \t\t Predicted survival: 22.62% \t 0\n",
            "337 \t\t Predicted survival: 0.00% \t 0\n",
            "338 \t\t Predicted survival: 24.12% \t 0\n",
            "339 \t\t Predicted survival: 0.00% \t 0\n",
            "340 \t\t Predicted survival: 14.18% \t 0\n",
            "341 \t\t Predicted survival: 0.00% \t 0\n",
            "342 \t\t Predicted survival: 53.84% \t 0 \t PREDIZIONE ERRATA\n",
            "343 \t\t Predicted survival: 99.61% \t 1\n",
            "344 \t\t Predicted survival: 10.10% \t 0\n",
            "345 \t\t Predicted survival: 41.31% \t 1 \t PREDIZIONE ERRATA\n",
            "346 \t\t Predicted survival: 25.10% \t 0\n",
            "347 \t\t Predicted survival: 3.94% \t 1 \t PREDIZIONE ERRATA\n",
            "348 \t\t Predicted survival: 24.60% \t 0\n",
            "349 \t\t Predicted survival: 57.94% \t 1\n",
            "350 \t\t Predicted survival: 93.81% \t 1\n",
            "351 \t\t Predicted survival: 14.02% \t 0\n",
            "352 \t\t Predicted survival: 33.50% \t 0\n",
            "353 \t\t Predicted survival: 19.88% \t 0\n",
            "354 \t\t Predicted survival: 42.17% \t 1 \t PREDIZIONE ERRATA\n",
            "355 \t\t Predicted survival: 0.00% \t 0\n",
            "356 \t\t Predicted survival: 96.97% \t 1\n",
            "357 \t\t Predicted survival: 0.01% \t 0\n",
            "358 \t\t Predicted survival: 0.00% \t 0\n",
            "359 \t\t Predicted survival: 40.51% \t 1 \t PREDIZIONE ERRATA\n",
            "360 \t\t Predicted survival: 0.52% \t 0\n",
            "361 \t\t Predicted survival: 62.73% \t 1\n",
            "362 \t\t Predicted survival: 57.07% \t 1\n",
            "363 \t\t Predicted survival: 0.65% \t 0\n",
            "364 \t\t Predicted survival: 99.96% \t 1\n",
            "365 \t\t Predicted survival: 63.97% \t 1\n",
            "366 \t\t Predicted survival: 23.79% \t 0\n",
            "367 \t\t Predicted survival: 89.73% \t 1\n",
            "368 \t\t Predicted survival: 100.00% \t 1\n",
            "369 \t\t Predicted survival: 23.47% \t 0\n",
            "370 \t\t Predicted survival: 15.18% \t 0\n",
            "371 \t\t Predicted survival: 100.00% \t 1\n",
            "372 \t\t Predicted survival: 0.00% \t 0\n",
            "373 \t\t Predicted survival: 20.46% \t 0\n",
            "374 \t\t Predicted survival: 84.67% \t 1\n",
            "375 \t\t Predicted survival: 99.25% \t 1\n",
            "376 \t\t Predicted survival: 29.78% \t 1 \t PREDIZIONE ERRATA\n",
            "377 \t\t Predicted survival: 19.83% \t 0\n",
            "378 \t\t Predicted survival: 28.03% \t 0\n",
            "379 \t\t Predicted survival: 0.44% \t 0\n",
            "380 \t\t Predicted survival: 0.00% \t 0\n",
            "381 \t\t Predicted survival: 0.49% \t 0\n",
            "382 \t\t Predicted survival: 60.09% \t 1\n",
            "383 \t\t Predicted survival: 44.85% \t 1 \t PREDIZIONE ERRATA\n",
            "384 \t\t Predicted survival: 19.23% \t 0\n",
            "385 \t\t Predicted survival: 79.06% \t 1\n",
            "386 \t\t Predicted survival: 0.03% \t 0\n",
            "387 \t\t Predicted survival: 19.17% \t 0\n",
            "388 \t\t Predicted survival: 0.67% \t 0\n",
            "389 \t\t Predicted survival: 7.06% \t 0\n",
            "390 \t\t Predicted survival: 98.80% \t 0 \t PREDIZIONE ERRATA\n",
            "391 \t\t Predicted survival: 77.83% \t 1\n",
            "392 \t\t Predicted survival: 12.36% \t 0\n",
            "393 \t\t Predicted survival: 0.01% \t 0\n",
            "394 \t\t Predicted survival: 1.61% \t 0\n",
            "395 \t\t Predicted survival: 88.96% \t 1\n",
            "396 \t\t Predicted survival: 0.12% \t 0\n",
            "397 \t\t Predicted survival: 99.97% \t 1\n",
            "398 \t\t Predicted survival: 0.19% \t 0\n",
            "399 \t\t Predicted survival: 0.05% \t 0\n",
            "400 \t\t Predicted survival: 97.27% \t 1\n",
            "401 \t\t Predicted survival: 19.57% \t 0\n",
            "402 \t\t Predicted survival: 100.00% \t 1\n",
            "403 \t\t Predicted survival: 97.89% \t 0 \t PREDIZIONE ERRATA\n",
            "404 \t\t Predicted survival: 76.87% \t 0 \t PREDIZIONE ERRATA\n",
            "405 \t\t Predicted survival: 51.11% \t 0 \t PREDIZIONE ERRATA\n",
            "406 \t\t Predicted survival: 14.80% \t 0\n",
            "407 \t\t Predicted survival: 55.16% \t 0 \t PREDIZIONE ERRATA\n",
            "408 \t\t Predicted survival: 83.03% \t 1\n",
            "409 \t\t Predicted survival: 47.48% \t 1 \t PREDIZIONE ERRATA\n",
            "410 \t\t Predicted survival: 80.79% \t 1\n",
            "411 \t\t Predicted survival: 95.02% \t 1\n",
            "412 \t\t Predicted survival: 31.61% \t 1 \t PREDIZIONE ERRATA\n",
            "413 \t\t Predicted survival: 11.76% \t 0\n",
            "414 \t\t Predicted survival: 98.04% \t 1\n",
            "415 \t\t Predicted survival: 0.45% \t 0\n",
            "416 \t\t Predicted survival: 19.37% \t 0\n",
            "417 \t\t Predicted survival: 27.97% \t 0\n",
            "\n",
            " - Totale predizioni corrette: 334\n",
            " - Totale predizioni errate: 84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3amQ5FUKzmO",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvl5oKqfYVUp",
        "colab_type": "text"
      },
      "source": [
        "Tramite i valori ottenuti è possibile generare una confuion_matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI9G4F86L0PN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_rounded = tf.round(tf.sigmoid(predictions)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqznYYsUK3rX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5226a3fa-f883-4408-9dd4-c09415013714"
      },
      "source": [
        "print(confusion_matrix(titanic_load_test_label['Survived'], predictions_rounded, normalize=None))"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[245  21]\n",
            " [ 63  89]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aw3JdMgaeSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}